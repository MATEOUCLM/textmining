---
title: "Trabajo de Text Mining | Proyecto <p> Text Mining aplicado a una novela de Charles Dickens"
subtitle: "Máster Universitario en Modelización y Análisis de Datos Económicos <p> (MUMADE)"
author: 'Autores: Bermann, M.A. & Pérez, R.S. [Grupo D]'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
lang: es
---

```{r setup, include = FALSE}
# Ajustes de los chunk
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      comment = '')
```

```{r inicio, include = FALSE}
# Limpieza inicial del entorno
rm(list = ls())
# Instalación de paquetes que no estén instalados
packages <- c("tidyr",
              "dplyr",
              "tidytext",
              "tidyverse",
              "gutenbergr",
              "tokenizers",
              "tm",
              "ggplot2",
              "igraph",
              "ggraph",
              "scales",
              "textdata",
              "stringr",
              "knitr",
              "wordcloud",
              "reshape2")
installed_packages <- packages %in% 
  rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# Activación de paquetes
library(tidyr)
library(dplyr)
library(tidytext)
library(tidyverse)
library(gutenbergr)
library(tokenizers)
library(tm)
library(ggplot2)
library(igraph)
library(ggraph)
library(scales)
library(textdata)
library(knitr)
library(wordcloud)
library(reshape2)
```

# Resumen 

El uso de técnicas analíticas avanzadas para aplicarlo a distintos ámbitos está empezando a ser una constante continua. Una de las técnicas que está proliferando en los últimos años es el análisis de discursos, mensajes, publicaciones en redes sociales, etc. Para ello, se utilizan las llamadas técnicas de minería de texto (text mining). Este creciente interés es el que se intentará abordar en este trabajo. Así, en este caso, se va a leer y analizar una famosa novela, pero la única diferencia es que, esta vez, lo hará el programa R por "nosotros2. De esta forma, se ha escogido la novela **Oliver Twist**, una obra del exponente de la novela social, Charles Dickens, el cual recoge en dicha obra un libro popular con una trama y un conjunto de ambientes que, como veremos, se caracterizan por la decadencia, las cuestiones trágicas, el pesimismo, etc. Además, se verán cambios de entorno según el capítulo analizado, con lo que se podrá ver, momento a momento, los cambios de guión gracias a a las técnicas de _text mining_ mencionadas.

# Procesamiento del texto

En primer lugar se ha **descargado e importado**, al entorno de trabajo, la novela, a través del [Project Gutenberg](https://www.gutenberg.org/ebooks/730), donde _Oliver Twist_ tiene la numeración [730](https://www.gutenberg.org/files/730/730-0.txt).

```{r importacion, include = FALSE}
# Importando la obra del Proyecto Gutenberg
olivertwist <- 
  gutenberg_download(c(730))
```

En segundo lugar, se ha ajustado el marco de análisis de la novela a partir del inicio del Capítulo I.

```{r ajuste1, include = FALSE}
# Ajustándonos al principio y final de la novela y otros ajustes
text_olivertwist <-
  olivertwist %>% 
  slice((114:18813)) %>% 
  select(2) %>% 
  pull() %>%
  map(trimws) %>%
  ifelse(. == "",
         "_salto_",
         .) %>%
  paste0(., collapse = " ") %>%
  strsplit(split = "_salto_") %>%
  map(trimws) %>%
  data.frame(stringsAsFactors = FALSE) %>%
  as_tibble() %>%
  {
    names(.) <- "texto"
    .
  }
```

En tercer lugar, se han eliminado las filas en blanco, así como los cambios de renglones vacíos.

```{r ajuste2, include = FALSE}
# Eliminando filas en blanco finales
text_olivertwist <-
  text_olivertwist %>% 
  slice((1:3894))
# Quitando renglones vacíos
text_olivertwist <-
  text_olivertwist %>%
  filter(!texto %in% c(" ", "")) %>%
  mutate_all(trimws)
```

En cuarto lugar, se han agrupado los párrafos por capítulos y se ha _tokenizado_.

```{r ajuste3, include = FALSE}
# Agrupando párrafos por capítulos
text_olivertwist %>%
  filter(grepl("CHAPTER",
               texto))
text_olivertwist <-
  text_olivertwist %>%
  mutate(capitulo = ifelse(grepl("CHAPTER", 
                                 texto), 
                           texto, NA)) %>%
  fill(capitulo) %>%
  filter(texto != capitulo)
# Tokenizando
tidy_olivertwist <- 
  text_olivertwist %>%
  unnest_tokens(word, texto) %>%
  anti_join(stop_words)
```

# Análisis de sentimientos

En este primer capítulo, se va a realizar un análisis _token_ por _token_ (en este caso, palabra por palabra) de la novela, determinando si estos corresponden a **sentimientos positivos o negativos**, a partir de la colección de palabras de _Bing_.

Se ha decidido utilizar el repositorio de palabras _Bing_ ya que el resto ofrecido por R categorizan las palabras en varios grupos, por lo que no son tan sencillos de representar e identificar. En este sentido, cabe decir que se ha encontrado muy interesante la fuente _"afinn"_, pero al tener un tercio de las palabras del repositorio de _Bing_ se ha decidido descartar.

Para realizar todo lo comentado se han importado las palabras del repositorio _Bing_ y se han cruzado los datos con las palabras que contiene la novela de Dickens, identificando así qué palabras se consideran "positivas" y cuáles "negativas" en dicha novela.

```{r sentimientos1, include = FALSE}
# Importando las palabras de bing
bing <- 
  get_sentiments("bing")
# Creando el objeto sentimiento que analiza las palabras de la novela que coinciden con las del repositorio bing
sentimiento <-
  left_join(x = tidy_olivertwist,
            y = bing,
            by = "word") %>% 
  count(word, 
        sentiment, 
        sort = TRUE)
# Eliminando del objeto sentimiento las palabras de la novela que no están en bing (missing values)
sentimiento <- 
  drop_na(sentimiento)
# Objeto que recoge las palabras que se repiten mas de 25 veces
sentimiento_filtrado <- 
  sentimiento %>% 
  filter(n > 25)
# Creando el objeto de palabras positivas
sentimiento_positivo <-
  sentimiento_filtrado %>% 
  filter(sentiment == "positive")
# Creando el objeto de palabras negativas
sentimiento_negativo <-
  sentimiento_filtrado %>%
  filter(sentiment == "negative")
```

## Análisis de sentimientos sobre la obra en conjunto

Así, en primer lugar, se puede obtener un gráfico de las **palabras "positivas"** más frecuentas en la novela de Dickens. Llama la atención que la palabra más frecuente es *master*, la cual, aunque se clasifique como positiva, en el contexto de la obra puede verse más como un signo de sumisión, y por lo tanto, negativa. También se observan palabras como _happy_ o _love_, que son eminentemente positivas. 

```{r sentimientos2, fig.align = 'center', fig.height = 5, fig.width = 10}
# Graficando la frecuencia de palabras positivas
ggplot(sentimiento_positivo,
       aes(word,
           n))+
  geom_point(color = 'green3',
             size = 4,
             shape = 10)+
  theme_bw(base_size = 11)+
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Palabras positivas más comunes")+
  ylab("Frecuencia")+
  xlab("Palabra")
```

En cuanto a las **palabras "negativas"**, si bien se descarta _Twist_, por ser el apellido de Oliver, el protagonista, estas palabras tienen una frecuencia acumulada mucho mayor que las palabras positivas, siendo palabras unívocas y que van en la línea de la trama de la novela. _Oscuro_, _pobre_, _frío_ o _muerto_ solo pueden ser interpretadas de un modo, y es ese ambiente de decadencia que describe continuamente la novela donde las injusticias, el maltrato y la pobreza son una constante en la vida del pequeño Oliver. Destaca especialmente también las palabras _muerte_ y _muerto_, dos palabras muy negativas que se reptien, ambas, 53 veces.

```{r sentimientos3, fig.align = 'center', fig.height = 5, fig.width = 10}
# Graficando la frecuencia de palabras negativas
ggplot(sentimiento_negativo,
       aes(word,
           n))+
  geom_point(color = 'red3',
             size = 4,
             shape = 10)+
  theme_bw(base_size = 11)+
  theme(axis.text.x = element_text(angle = 90))+
  ggtitle("Palabras negativas más comunes")+
  ylab("Frecuencia")+
  xlab("Palabra")
```

Si se refleja en una tabla la información anterior, se podrá ver cómo la frecuencia de palabras negativas repetidas es mucho mayor que la frecuencia de palabras positivas. En total, hay más de dos veces palabras negativas (`r sum(sentimiento_negativo$n)`) que positivas (`r sum(sentimiento_positivo$n)`), aun contando y teniendo en cuenta *master* como palabra postiva.

```{r sentimientos4}
sentimiento_positivo %>% 
  head(10) %>% 
  kable()
sentimiento_negativo %>% 
  head(10) %>% 
  kable()
```

## Análisis de sentimientos por capítulos

Una vez realizado el análisis de los sentimientos de la obra en su conjunto, teniendo en cuenta la evolución de los escenarios y de lo que transcurre a lo largo de dicha obra, puede ser de interés ver **cómo se diferencias los distintos sentimientos a lo largo de los capítulos**. Para ello, se han agrupado las palabras positivas y negativas por capítulos.

```{r sentimientos5}
sentimiento_capitulo <-
  left_join(x = tidy_olivertwist,
            y = bing,
            by = "word") %>% 
  drop_na()
sentimiento_capitulo <-
  sentimiento_capitulo %>% 
  group_by(capitulo)
capitulo_positivo <-
  sentimiento_capitulo %>%
  filter(sentiment == "positive")
capitulo_negativo <-
  sentimiento_capitulo %>%
  filter(sentiment == "negative")
```

Así, en primer lugar, si se analizan las **palabras positivas**, se observa cómo hay dos secciones claves en las que hay más palabras positivas. Primero, en los capítulos XII y XIV hay una mayor frecuencia de palabras positivas. Veamos únicamente cómo se llama, por ejemplo, el capítulo XII. La segunda sección de palabras positivas frecuentes se da justo antes de finalizar en los capítulos XXXII, XXXIII, XXXIV y XXXVI. Sólo hace falta fijarse en el capítulo XXXII, donde Oliver Twist emprende diferentes amistades y aumenta su felicidad y bienestar respecto a anteriores situaciones.

```{r sentimientos6}
capitulo_positivo %>%
  group_by(capitulo) %>%
  count(sentiment)
```

En segundo lugar, si se analizan las **palabras negativas**, en primer lugar se observan que sus frecuencias son mucho mayores. Parece paradójico que la mayor concentración de estos sentimientos negativos se dan al final de la obra, donde casi se alcanzan en uno de los capítulos las 200 palabras negativas.

```{r sentimientos7}
capitulo_negativo %>%
  group_by(capitulo) %>%
  count(sentiment)
```

# Nube de palabras

En este apartado, haremos una nube de palabras para representar las palabras más comunes a lo largo del libro. Así, no sólo veremos las más frecuentes sino que a través del tamaño veremos su importancia de un solo vistazo. 

Llevamos a cabo este proceso dos veces: una para todo el vocabulario del libro

```{r nube1}
tidy_olivertwist %>%
 count(word) %>%
 with(wordcloud(word,
                n,
                max.words = 150))
```

En la que destacan personajes (Oliver Twist, Bumble, Fagin, un judío -y no judíos en plural, con lo que es posible que un personaje sea caracterizado así en vez de una comunidad-, un doctor, Noah), elementos que nos dan una visión de la ambientación( _boy_, _girl_, _gentleman_, _sir_, _child_, _fire_, 
_hat_) que es de la vida infantil de la inglaterra de los años 1830. Por último, hay palabras que bien podrían estar en cualquier libro ( _door_, _head_, _eyes_, _time_, _hand_, _day_, _night_ ).

En segundo lugar, hacemos una nube de palabras sólo con las palabras que tienen un significado positivo o negativo, de manera que sabemos que tendrán un significado relevante para nuestro análisis

```{r nube2}
tidy_olivertwist %>%
 inner_join(bing) %>%
 count(word,
       sentiment,
       sort = TRUE) %>%
 acast(word ~ sentiment,
       value.var = "n",
       fill = 0) %>%
 comparison.cloud(colors = c("red3",
                             "green3"),
 max.words = 150)
```

En la que vemos, de igual manera que vimos gracias a la tabla en el anterior apartado, que master tiene una frecuencia muy alta. Dentro del resto de palabras positivas, vemos algunas que tienen un deje de tristeza, como _heaven_, _quiet_, _silent_ o incluso _fine_ (recordemos que también significa multa). Las palabras negativas que más aparecen son _poor_, _cold_, _dark_ y _dead_. Aparece twist pero al ser el apellido del protagonista, no la debemos tomar en cuenta como palabra negativa. 

# Frecuencia de palabras

Vamos a explorar qué palabras aparecen más veces en el libro, a través de una tabla y de un gráfico. Ya que es la misma información que en la nube de palabras número uno, veremos muchas palabras repetidas, sin embargo, al estar en un formato menos gráfico pero más completo y preciso, en el que veremos cuántas veces se repite exactamente cada palabra, podremos ver con más detalle las características del texto.


```{r frec1}
# Palabras más frecuentes
tidy_olivertwist %>%
  count(word,
        sort = TRUE)
```
Vemos que la palabra más frecuente es el nombre de pila del protagonista, que se menciona casi 700 veces. Llaman la atención palabras de estilo que se repiten mucho,  como _replied_ , _time_ o incluso _dear_. También son muy frecuentes nombres de personajes, como Fagin, Sikes o  Bumble. 
Se nos ha escapado alguna palabra vacía como _don't_ o _it's_ que al ser contracciones no aparecen en la base de stop words que hemos usado.
También podemos navegar en las palabras que eran demasiado raras para aparecer en la nube de texto pero son suficienteme frecuentes como para tener un impacto en el texto, como los verbos usados( _spoke_, _stood_, _brittles_, _stopped_, _appeared_, _fell_, _cried_) en el texto, que también nos da una idea de lo que pasa en el libro, con acciones físicas como caídas y paradas y acciones más literarias como hablar, aparecer o llorar.
```{r frec2}
# Gráfico de frecuencia de palabras
frequency <-
  tidy_olivertwist %>%
  count(word,
        sort = TRUE,) %>% 
  mutate(proportion = n / sum(n))
frequency <- frequency %>% 
  slice(1:75)
ggplot(frequency,
       aes(word,
           proportion))+
  geom_point(color = "red4")+
  theme_light()+
  theme(axis.text.x = element_text(angle = 90),
        axis.text = element_text(size = 7))+
  ggtitle("Palabras más utilizadas")+
  ylab("Frecuencia") +
  xlab("Palabra")
```
El gráfico nos sirve para ver mejor las frecuencias de cada palabra, ya que en el resto de representaciones hemos visto la frecuencia en valores absolutos. Desde luego, al ser una obra extensa, no hay palabras tan comunes. Si fuese un cuento, veríamos frecuencias relativas más altas.
# Conclusiones

Párrafo 1

Párrafo 2

# Referencias

En esta sección se incluyen las referencias bibliográficas utilizadas para el desarrollo del proyecto.

[Dickens, C. (1837). Oliver Twist. Project Gutenberg. https://www.gutenberg.org/ebooks/730.](https://www.gutenberg.org/ebooks/730)

Gutiérrez, M.J. (2022). Text mining con R. Aprendizaje estadístico y otras técnicas avanzadas. Máster Universitario en Modelización y Análisis de Datos Económicos. Universidad de Castilla-La Mancha.

[El Cronovisor (2017). Charles Dickens, genio de la crítica social. Episodio 4. https://open.spotify.com/episode/3lLBJHZGY3verRFV6ptEbS?si=9_xGOeGWTiW4ijZuIexBeg&utm_source=copy-link](https://open.spotify.com/episode/3lLBJHZGY3verRFV6ptEbS?si=9_xGOeGWTiW4ijZuIexBeg&utm_source=copy-link)

[Silge, J. & Robinson D. (2022). Text Mining with R. https://www.tidytextmining.com/tidytext.html.](https://www.tidytextmining.com/tidytext.html)

# Anexos

## Anexo 1. Datos de la sesión

En esta sección se recogen los datos de la sesión utilizada para elaborar este informe. Es fundamental observar la versión de R, así como las versiones de los paquetes bajo los cuales se ha ejecutado el código o *script*.

```{r}
sessionInfo()
```
